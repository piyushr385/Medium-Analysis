{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e0b427",
   "metadata": {},
   "source": [
    "# Medium Archive Data-Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f58f37",
   "metadata": {},
   "source": [
    "* In This notebook we will clean the data that is extracted from Mediums archive pages\n",
    "* Each archive page is associated to a story-tag and is a collection of Medium timeline cards organized by date.\n",
    "* Data was Scraped from the mediums archive pages using selenium and beautifulsoup.\n",
    "* The data was pulled from popular Medium story-tag archives. Each archive was scraped for each day between Jan 1, 2019 and Dec   12, 2019.\n",
    "* The Tags Scraped: data-science,python,ai,machine-learning,deep-learning,big-data,computer-vision,nlp.\n",
    "* The analysis is specially for field of Data-Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ed00e",
   "metadata": {},
   "source": [
    "# Purpose of the Data\n",
    "1. To create a performance metric for Medium's authors, so they can compare their work to the rest of Medium.\n",
    "2. To compare the performance of authors and publications on Medium.\n",
    "3. To create a leaderboard of the top performing authors and publications in each tag .\n",
    "4. To find the differences that distinguish well-received articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb2b25f",
   "metadata": {},
   "source": [
    "# Structure of the data\n",
    "* Title\n",
    "* Subtitle\n",
    "* Image (yes/no)\n",
    "* Author\n",
    "* Publication\n",
    "* Year - Month - Day\n",
    "* Tag\n",
    "* Reading Time\n",
    "* Claps\n",
    "* Comment (yes/no)\n",
    "* Story Url\n",
    "* Author URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6cae02",
   "metadata": {},
   "source": [
    "# Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b3d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d90e565",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15bff525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "      <th>url</th>\n",
       "      <th>Author_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Getting Started With Google Colab</td>\n",
       "      <td>A Simple Tutorial for the Frustrated and Confused</td>\n",
       "      <td>1</td>\n",
       "      <td>Anne Bonner</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ai</td>\n",
       "      <td>8</td>\n",
       "      <td>3.2K</td>\n",
       "      <td>0</td>\n",
       "      <td>https://towardsdatascience.com/getting-started...</td>\n",
       "      <td>https://towardsdatascience.com/@annebonner?sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deep learning  ()</td>\n",
       "      <td>2018  Artificial intelligence</td>\n",
       "      <td>1</td>\n",
       "      <td>HD COE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ai</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/@hadee2531earvesdrop/deep-l...</td>\n",
       "      <td>https://medium.com/@hadee2531earvesdrop?source...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 Trends for AI in 2019</td>\n",
       "      <td>Ethics, driverless cars, cashierless stores, c...</td>\n",
       "      <td>1</td>\n",
       "      <td>David Vandegrift</td>\n",
       "      <td>Predict</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ai</td>\n",
       "      <td>5</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/predict/5-trends-for-ai-in-...</td>\n",
       "      <td>https://medium.com/@DavidVandegrift?source=tag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title  \\\n",
       "0  Getting Started With Google Colab   \n",
       "1                  Deep learning  ()   \n",
       "2            5 Trends for AI in 2019   \n",
       "\n",
       "                                            Subtitle  Image            Author  \\\n",
       "0  A Simple Tutorial for the Frustrated and Confused      1       Anne Bonner   \n",
       "1                      2018  Artificial intelligence      1            HD COE   \n",
       "2  Ethics, driverless cars, cashierless stores, c...      1  David Vandegrift   \n",
       "\n",
       "            Publication  Year  Month  Day Tag  Reading_Time Claps  Comment  \\\n",
       "0  Towards Data Science  2019      1    1  ai             8  3.2K        0   \n",
       "1                   NaN  2019      1    1  ai             3    55        0   \n",
       "2               Predict  2019      1    1  ai             5   278        0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://towardsdatascience.com/getting-started...   \n",
       "1  https://medium.com/@hadee2531earvesdrop/deep-l...   \n",
       "2  https://medium.com/predict/5-trends-for-ai-in-...   \n",
       "\n",
       "                                          Author_url  \n",
       "0  https://towardsdatascience.com/@annebonner?sou...  \n",
       "1  https://medium.com/@hadee2531earvesdrop?source...  \n",
       "2  https://medium.com/@DavidVandegrift?source=tag...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_files = glob.glob(\"TAG_SCRAPES/*.csv\")\n",
    "\n",
    "frames =[]\n",
    "for file in tech_files:\n",
    "    #all of the seperate scrapes from different tags\n",
    "    df = pd.read_csv(file)\n",
    "    frames.append(df)\n",
    "medium = pd.concat(frames)\n",
    "medium.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b0512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles scraped (before cleaning):  117178\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of articles scraped (before cleaning): \",medium.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13abed48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title           object\n",
       "Subtitle        object\n",
       "Image            int64\n",
       "Author          object\n",
       "Publication     object\n",
       "Year             int64\n",
       "Month            int64\n",
       "Day              int64\n",
       "Tag             object\n",
       "Reading_Time     int64\n",
       "Claps           object\n",
       "Comment          int64\n",
       "url             object\n",
       "Author_url      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43581553",
   "metadata": {},
   "source": [
    "# Converting Strings to Floats\n",
    "* Before we can work with the data we need to convert the \"Claps\" column from string to float values. Note that the Object\n",
    "  datatype is non-numeric. There is also an issue with Claps in the form of \"3.2K\", rather than \"3200\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3a141",
   "metadata": {},
   "source": [
    "# Reformatting Clap Information to Floats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9586e73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clap dtype:  float64\n"
     ]
    }
   ],
   "source": [
    "#Claps entries higher than 999 are written \"3.2K\"\n",
    "# here we remove the \"K\", convert the string to float, then multiply by 1000.\n",
    "numeric_claps = []\n",
    "for x in medium.Claps:\n",
    "    if \"K\" in x:\n",
    "        numeric_claps.append(float(x[:-1])*1000)\n",
    "    else:\n",
    "        numeric_claps.append(x)\n",
    "medium[\"Claps\"] = numeric_claps\n",
    "medium[\"Claps\"] = pd.to_numeric(medium[\"Claps\"])\n",
    "print(\"Clap dtype: \", medium.dtypes[\"Claps\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e52d1c9",
   "metadata": {},
   "source": [
    "# Removing Comment Entries\n",
    "* Comment entries have been encoded into the data with the Comment column. Since these entries are not articles, we remove them   in the following script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5354fc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Entries to be removed:  3901\n",
      "Percentage of remaining data:  3.33 %\n"
     ]
    }
   ],
   "source": [
    "no_comm = medium[medium.Comment==0]\n",
    "no_comm = no_comm.drop([\"Comment\"], axis=1)\n",
    "print(\"Number of Entries to be removed: \", medium.shape[0]-no_comm.shape[0])\n",
    "print(\"Percentage of remaining data: \" ,round(((medium.shape[0]-no_comm.shape[0])/medium.shape[0])*100,2), \"%\")\n",
    "medium = no_comm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3a46b",
   "metadata": {},
   "source": [
    "# Cleaning up Urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a82ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://towardsdatascience.com/@annebonner?source=tag_archive---------0-----------------------\n",
      "https://medium.com/@hadee2531earvesdrop?source=tag_archive---------1-----------------------\n",
      "https://medium.com/@DavidVandegrift?source=tag_archive---------2-----------------------\n"
     ]
    }
   ],
   "source": [
    "#before\n",
    "for i in range(3):\n",
    "    print(medium.Author_url.values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "971886cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium.url = medium.url.str.split(\"?\", expand=True)\n",
    "medium.Author_url = medium.Author_url.str.split(\"?\", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97b06351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://towardsdatascience.com/@annebonner\n",
      "https://medium.com/@hadee2531earvesdrop\n",
      "https://medium.com/@DavidVandegrift\n"
     ]
    }
   ],
   "source": [
    "#after\n",
    "for i in range(3):\n",
    "    print(medium.Author_url.values[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a12ba9",
   "metadata": {},
   "source": [
    "# Checking for Non Entries in the Data\n",
    "## All NaNs in Each Column\n",
    "* We only have missing values in Title, Subtitle, or Publication. NaNs in publication column because not all articles are         published."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e3e227b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs\n",
      "Title                 3522\n",
      "Subtitle             45760\n",
      "Image                    0\n",
      "Author                 171\n",
      "Publication          59249\n",
      "Year                     0\n",
      "Month                    0\n",
      "Day                      0\n",
      "Tag                      0\n",
      "Reading_Time             0\n",
      "Claps                    0\n",
      "url                      0\n",
      "Author_url             171\n",
      "\n",
      "Total Entries:   113277\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of NaNs\")\n",
    "for x in range(13):\n",
    "    print(\"%-15s %10d\" % (medium.columns.values[x], medium.iloc[:,x].isna().sum()))\n",
    "print()\n",
    "print(\"Total Entries:  \", medium.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6e1ec8",
   "metadata": {},
   "source": [
    "# Remove NaN Authors\n",
    "* The cards on the archive timeline have neither author nor publication. Since there are only a coulple hundred entries without  an author, I choose to remove these from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1268c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium = medium[medium.Author.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04914e4f",
   "metadata": {},
   "source": [
    "# NaN Title and Subtitle Entries\n",
    "\n",
    "* Sometimes when scraping the archive page, Titles are in weird formats. The result, some articles titles are scraped as         subtitles.\n",
    "\n",
    "* Here is a breakdown of the NonEntries in Title/SubTitle Columns. I choose to keep these in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9d93c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaN Title Entries:  3519\n",
      "Entries with NaN Title but existing SubTitle:  1647\n",
      "Entries with neither title nor subtitle:  1872\n"
     ]
    }
   ],
   "source": [
    "#Total entries with no Title\n",
    "print(\"Total NaN Title Entries: \", medium[medium.Title.isnull()].shape[0])\n",
    "\n",
    "#Entries with no title but with a subtitle\n",
    "print(\"Entries with NaN Title but existing SubTitle: \",medium[(medium.Title.isnull() & medium.Subtitle.notnull())].shape[0])\n",
    "\n",
    "#Neither Possible explanations?\n",
    "print(\"Entries with neither title nor subtitle: \", medium[(medium.Title.isnull() & medium.Subtitle.isnull())].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa73a6",
   "metadata": {},
   "source": [
    "# Total Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43ba7f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs\n",
      "Title                 3519\n",
      "Subtitle             45715\n",
      "Image                    0\n",
      "Author                   0\n",
      "Publication          59241\n",
      "Year                     0\n",
      "Month                    0\n",
      "Day                      0\n",
      "Tag                      0\n",
      "Reading_Time             0\n",
      "Claps                    0\n",
      "url                      0\n",
      "Author_url               0\n",
      "\n",
      "Total Entries:   113106\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of NaNs\")\n",
    "for x in range(13):\n",
    "    print(\"%-15s %10d\" % (medium.columns.values[x], medium.iloc[:,x].isna().sum()))\n",
    "print()\n",
    "print(\"Total Entries:  \", medium.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6026fc",
   "metadata": {},
   "source": [
    "# Removing Duplicate Articles (Multi-tagged)\n",
    "* Medium allows an author to include 5 tags for each story.\n",
    "\n",
    "* When we scraped the archive page, we scraped each individual tag. As a result, stories will appear multiple times in our data   (with different tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a909829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are:  58849 Duplicated entries.\n",
      "Unique posts with multiple tags:  25806\n"
     ]
    }
   ],
   "source": [
    "#one hot encode the tags \n",
    "medium = pd.get_dummies(medium, columns = [\"Tag\"])\n",
    "\n",
    "#multi_tags is all entries in the dataset that have duplicates (includes all duplicates)\n",
    "multi_tags = medium[medium.duplicated(subset=[\"url\", \"Year\", \"Month\",\"Day\"], keep=False)]\n",
    "print(\"There are: \", multi_tags.shape[0], \"Duplicated entries.\")\n",
    "print(\"Unique posts with multiple tags: \", multi_tags.shape[0]- medium[medium.duplicated(subset=[\"url\", \"Year\", \"Month\",\"Day\"],\n",
    "      keep=\"last\")].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21dbf97",
   "metadata": {},
   "source": [
    "# Combining each multitagged article into ONE row\n",
    "* Combine the onehot encoded tags of each multiposted article into one entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e58da446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag_ai</th>\n",
       "      <th>Tag_big-data</th>\n",
       "      <th>Tag_computer-vision</th>\n",
       "      <th>Tag_data-science</th>\n",
       "      <th>Tag_deep-learning</th>\n",
       "      <th>Tag_machine-learning</th>\n",
       "      <th>Tag_nlp</th>\n",
       "      <th>Tag_python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tag_ai  Tag_big-data  Tag_computer-vision  Tag_data-science  \\\n",
       "0       0             0                    0                 1   \n",
       "1       1             0                    0                 0   \n",
       "\n",
       "   Tag_deep-learning  Tag_machine-learning  Tag_nlp  Tag_python  \n",
       "0                  0                     1        0           0  \n",
       "1                  0                     1        0           0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#groupby urls since a unique story has a unique url, sum the rows for all tags\n",
    "#now all tag vectors will be on one line\n",
    "gb = multi_tags.groupby([\"url\",\"Year\",\"Month\",\"Day\"]).sum().reset_index()\n",
    "tags = gb.iloc[:,7:].copy()\n",
    "tags.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b280485b",
   "metadata": {},
   "source": [
    "* Remove all but one of each duplicate entry, then sort, so rows match up with the groupby dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "947231cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>url</th>\n",
       "      <th>Author_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digging for value in the text mines</td>\n",
       "      <td>The oil and gas industrys new toolset is trans...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jesse Lord</td>\n",
       "      <td>Bransjebloggenmin</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://3min.io/digging-for-value-in-the-text-...</td>\n",
       "      <td>https://3min.io/@jesse_81306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who killed JFK?</td>\n",
       "      <td>Knowledge Mining can help us solve mysteries o...</td>\n",
       "      <td>1</td>\n",
       "      <td>Izabela Hawry ko</td>\n",
       "      <td>Bransjebloggenmin</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>https://3min.io/who-killed-jfk-9aa4514442b2</td>\n",
       "      <td>https://3min.io/@izabela.hawrylko</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title  \\\n",
       "0  Digging for value in the text mines   \n",
       "1                      Who killed JFK?   \n",
       "\n",
       "                                            Subtitle  Image            Author  \\\n",
       "0  The oil and gas industrys new toolset is trans...      1        Jesse Lord   \n",
       "1  Knowledge Mining can help us solve mysteries o...      1  Izabela Hawry ko   \n",
       "\n",
       "         Publication  Year  Month  Day  Reading_Time  Claps  \\\n",
       "0  Bransjebloggenmin  2019      2   27             4    0.0   \n",
       "1  Bransjebloggenmin  2019      6    6             5    2.0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://3min.io/digging-for-value-in-the-text-...   \n",
       "1        https://3min.io/who-killed-jfk-9aa4514442b2   \n",
       "\n",
       "                          Author_url  \n",
       "0       https://3min.io/@jesse_81306  \n",
       "1  https://3min.io/@izabela.hawrylko  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep only one entry of each duplicated article\n",
    "sort = multi_tags[~multi_tags.duplicated(subset=[\"url\",\"Year\", \"Month\",\"Day\"], keep=\"first\")]\n",
    "\n",
    "#sort the entry to put it in the exact same order as the groupby above\n",
    "sort = sort.sort_values([\"url\",\"Year\",\"Month\",\"Day\"]).reset_index().drop(\"index\",axis=1)\n",
    "\n",
    "#keep only the combined tags for a merge later\n",
    "sort = sort.iloc[:,:12].copy()\n",
    "sort.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577e86b",
   "metadata": {},
   "source": [
    "* Check that the two frames are aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d1469cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check the two dataframes match up\n",
    "(sort.url==gb.url).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c76cb1",
   "metadata": {},
   "source": [
    "* Combine the two dataframes horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "324e4f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>url</th>\n",
       "      <th>Author_url</th>\n",
       "      <th>Tag_ai</th>\n",
       "      <th>Tag_big-data</th>\n",
       "      <th>Tag_computer-vision</th>\n",
       "      <th>Tag_data-science</th>\n",
       "      <th>Tag_deep-learning</th>\n",
       "      <th>Tag_machine-learning</th>\n",
       "      <th>Tag_nlp</th>\n",
       "      <th>Tag_python</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digging for value in the text mines</td>\n",
       "      <td>The oil and gas industrys new toolset is trans...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jesse Lord</td>\n",
       "      <td>Bransjebloggenmin</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://3min.io/digging-for-value-in-the-text-...</td>\n",
       "      <td>https://3min.io/@jesse_81306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who killed JFK?</td>\n",
       "      <td>Knowledge Mining can help us solve mysteries o...</td>\n",
       "      <td>1</td>\n",
       "      <td>Izabela Hawry ko</td>\n",
       "      <td>Bransjebloggenmin</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>https://3min.io/who-killed-jfk-9aa4514442b2</td>\n",
       "      <td>https://3min.io/@izabela.hawrylko</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title  \\\n",
       "0  Digging for value in the text mines   \n",
       "1                      Who killed JFK?   \n",
       "\n",
       "                                            Subtitle  Image            Author  \\\n",
       "0  The oil and gas industrys new toolset is trans...      1        Jesse Lord   \n",
       "1  Knowledge Mining can help us solve mysteries o...      1  Izabela Hawry ko   \n",
       "\n",
       "         Publication  Year  Month  Day  Reading_Time  Claps  \\\n",
       "0  Bransjebloggenmin  2019      2   27             4    0.0   \n",
       "1  Bransjebloggenmin  2019      6    6             5    2.0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://3min.io/digging-for-value-in-the-text-...   \n",
       "1        https://3min.io/who-killed-jfk-9aa4514442b2   \n",
       "\n",
       "                          Author_url  Tag_ai  Tag_big-data  \\\n",
       "0       https://3min.io/@jesse_81306       0             0   \n",
       "1  https://3min.io/@izabela.hawrylko       1             0   \n",
       "\n",
       "   Tag_computer-vision  Tag_data-science  Tag_deep-learning  \\\n",
       "0                    0                 1                  0   \n",
       "1                    0                 0                  0   \n",
       "\n",
       "   Tag_machine-learning  Tag_nlp  Tag_python  \n",
       "0                     1        0           0  \n",
       "1                     1        0           0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#smoosh em\n",
    "combined = pd.concat([sort, tags], axis=1, sort=False)\n",
    "combined.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def7f9ef",
   "metadata": {},
   "source": [
    "* Remove all duplicates from original dataframe, append combined entries to the bottom of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a806439c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of duplicate rows deleted:  33043\n"
     ]
    }
   ],
   "source": [
    "before = medium.shape[0]\n",
    "\n",
    "#Remove all duplicates articles with same date title and author\n",
    "medium = medium[~medium.duplicated(subset=[\"url\", \"Year\", \"Month\",\"Day\"], keep=False)]\n",
    "#Add the combined data that we made in the last two scripts to the end of the datafream\n",
    "dframes = [medium, combined]\n",
    "#merge the two dataframes\n",
    "medium = pd.concat(dframes)\n",
    "\n",
    "after = medium.shape[0]\n",
    "print(\"# of duplicate rows deleted: \", before-after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6abccb",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe80d35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of after cleaning:  80063\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Number of after cleaning: \", medium.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1da56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "medium.to_csv(\"Medium_Clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa86f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
